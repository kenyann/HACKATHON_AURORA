{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import bs4\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyPDFLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model='gpt-4o-mini', api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1. Load, chunk and index the contents of the blog to create a retriever.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "# 2. Incorporate the retriever into a question-answering chain.\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is the process of breaking down a complicated task into smaller, more manageable steps. This can be achieved using techniques like Chain of Thought (CoT), which encourages the model to think step by step, or Tree of Thoughts, which explores multiple reasoning possibilities for each step. By decomposing tasks, it becomes easier to understand and solve complex problems effectively.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is Task Decomposition?\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"proposals/file_10.pdf\")\n",
    "docs = loader.load()\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Paradox of Choice is a phenomenon where an abundance of options can lead to less happiness, less satisfaction, and a reduced ability to make a decision. It highlights how having too many choices can overwhelm consumers, making it difficult for them to make a decision at all.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"What is definition of Paradox of Choice\"})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf(file_path):\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    \n",
    "    return \" \".join([doc.page_content for doc in docs])\n",
    "    \n",
    "def summarize(user_input, file_path=None):\n",
    "    if file_path:\n",
    "        user_input = extract_pdf(file_path)\n",
    "    \n",
    "    print(user_input)\n",
    "    predefined_sections = {\n",
    "        \"Introduction\": \"\",\n",
    "        \"Objectives\": \"\",\n",
    "        \"Methodology\": \"\",\n",
    "        \"Results\": \"\",\n",
    "        \"Conclusion\": \"\"\n",
    "    }\n",
    "\n",
    "    system_prompt = (\n",
    "        f\"You are an assistant for document summarize tasks. Summarize the content and categorize it into these sections: {list(predefined_sections.keys())}\"\n",
    "        \"If a section lacks sufficient information, leave it empty and indicate that more input is needed.\"\n",
    "        \"answer concise.\"\n",
    "    )\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"input\": user_input})\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "# Example usage\n",
    "file_path = 'summarize.txt'\n",
    "text_content = read_text_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal for Planogram Evaluation Using AI\n",
      "\n",
      "Introduction\n",
      "Efficient merchandising is critical for optimizing shelf space, enhancing customer experience, and driving sales. Planograms—visual representations of a store's layout—are integral to achieving this, ensuring product placement aligns with business goals. However, evaluating planograms for compliance, performance, and customer impact is labor-intensive and prone to inconsistencies.\n",
      "\n",
      "Leveraging artificial intelligence (AI) offers a transformative approach. AI-powered solutions can analyze planograms efficiently, providing actionable insights to optimize layouts, ensure compliance, and boost profitability. This proposal outlines a comprehensive plan for implementing AI-based planogram evaluation.\n",
      "\n",
      "Objectives\n",
      "Automate Planogram Evaluation: Reduce the time and effort required to assess planogram compliance and effectiveness.\n",
      "Improve Accuracy: Minimize errors and inconsistencies inherent in manual evaluations.\n",
      "Optimize Shelf Performance: Provide actionable insights to enhance product visibility, customer satisfaction, and sales.\n",
      "Enable Continuous Improvement: Use AI analytics to adapt and improve planograms over time based on performance data.\n",
      "Methodology\n",
      "Data Collection:\n",
      "\n",
      "Gather planogram data, including layouts, product SKUs, and category placements.\n",
      "Capture shelf images or real-time data from IoT-enabled devices and cameras in stores.\n",
      "AI Model Development:\n",
      "\n",
      "Develop machine learning (ML) models for image recognition and natural language processing (NLP) to assess compliance and layout adherence.\n",
      "Train models on historical sales, customer traffic patterns, and planogram data to identify optimal layouts.\n",
      "Evaluation Process:\n",
      "\n",
      "Use computer vision to compare planograms against shelf images, detecting discrepancies like missing or misplaced products.\n",
      "Apply predictive analytics to evaluate how layout changes affect sales and customer behavior.\n",
      "Dashboard and Reporting:\n",
      "\n",
      "Build an interactive dashboard for stakeholders to view compliance scores, key performance indicators (KPIs), and recommendations.\n",
      "Provide detailed reports for actionable insights.\n",
      "Pilot Testing and Rollout:\n",
      "\n",
      "Conduct a pilot in select stores, refine the AI models based on results, and scale implementation across all locations.\n",
      "Results\n",
      "Through pilot testing, the following outcomes are anticipated:\n",
      "\n",
      "Increased Efficiency: Planogram evaluations completed in hours instead of days.\n",
      "Improved Accuracy: Over 95% accuracy in compliance detection compared to manual evaluations.\n",
      "Higher Sales Conversion Rates: Optimized layouts leading to a measurable increase in sales.\n",
      "Scalable Insights: AI-driven insights applicable across multiple locations, reducing operational inefficiencies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = summarize(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Introduction**  \n",
      "Efficient merchandising is critical for optimizing shelf space, enhancing customer experience, and driving sales. Planograms—visual representations of a store's layout—are integral to achieving this, ensuring product placement aligns with business goals. However, evaluating planograms for compliance, performance, and customer impact is labor-intensive and prone to inconsistencies. Leveraging artificial intelligence (AI) offers a transformative approach to analyze planograms efficiently, providing actionable insights to optimize layouts, ensure compliance, and boost profitability.\n",
      "\n",
      "**Objectives**  \n",
      "- Automate Planogram Evaluation: Reduce the time and effort required to assess planogram compliance and effectiveness.  \n",
      "- Improve Accuracy: Minimize errors and inconsistencies inherent in manual evaluations.  \n",
      "- Optimize Shelf Performance: Provide actionable insights to enhance product visibility, customer satisfaction, and sales.  \n",
      "- Enable Continuous Improvement: Use AI analytics to adapt and improve planograms over time based on performance data.  \n",
      "\n",
      "**Methodology**  \n",
      "- **Data Collection:** Gather planogram data, including layouts, product SKUs, and category placements; capture shelf images or real-time data from IoT-enabled devices and cameras in stores.  \n",
      "- **AI Model Development:** Develop machine learning (ML) models for image recognition and natural language processing (NLP) to assess compliance and layout adherence; train models on historical sales, customer traffic patterns, and planogram data to identify optimal layouts.  \n",
      "- **Evaluation Process:** Use computer vision to compare planograms against shelf images, detecting discrepancies like missing or misplaced products; apply predictive analytics to evaluate how layout changes affect sales and customer behavior.  \n",
      "- **Dashboard and Reporting:** Build an interactive dashboard for stakeholders to view compliance scores, key performance indicators (KPIs), and recommendations; provide detailed reports for actionable insights.  \n",
      "- **Pilot Testing and Rollout:** Conduct a pilot in select stores, refine the AI models based on results, and scale implementation across all locations.  \n",
      "\n",
      "**Results**  \n",
      "Through pilot testing, the following outcomes are anticipated:  \n",
      "- Increased Efficiency: Planogram evaluations completed in hours instead of days.  \n",
      "- Improved Accuracy: Over 95% accuracy in compliance detection compared to manual evaluations.  \n",
      "- Higher Sales Conversion Rates: Optimized layouts leading to a measurable increase in sales.  \n",
      "- Scalable Insights: AI-driven insights applicable across multiple locations, reducing operational inefficiencies.  \n",
      "\n",
      "**Conclusion**  \n",
      "[More input needed]\n"
     ]
    }
   ],
   "source": [
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aurora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
