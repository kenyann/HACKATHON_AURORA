{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hub5914358079.openai.azure.com/ \n",
      " gpt-35-turbo \n",
      " BASwuOBWAv3IM8baCDoOMbK3vVy9J01FD0BQiqizCygAsYcGLODYJQQJ99AKACmepeSXJ3w3AAAAACOGHcU9\n"
     ]
    }
   ],
   "source": [
    "endpoint = os.getenv(\"ENDPOINT_URL\")  \n",
    "deployment = os.getenv(\"DEPLOYMENT_NAME\")  \n",
    "subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "print(endpoint, '\\n', deployment, '\\n', subscription_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-AUBdOOPrkuZseK3N1sNX5332k935t\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"Hello! I am an AI assistant here to help you find information. What can I help you with today?\",\n",
      "        \"role\": \"assistant\"\n",
      "      },\n",
      "      \"content_filter_results\": {\n",
      "        \"hate\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"self_harm\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"sexual\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        },\n",
      "        \"violence\": {\n",
      "          \"filtered\": false,\n",
      "          \"severity\": \"safe\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1731757926,\n",
      "  \"model\": \"gpt-35-turbo\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 22,\n",
      "    \"prompt_tokens\": 20,\n",
      "    \"total_tokens\": 42\n",
      "  },\n",
      "  \"prompt_filter_results\": [\n",
      "    {\n",
      "      \"prompt_index\": 0,\n",
      "      \"content_filter_results\": {}\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "client = AzureOpenAI(  \n",
    "        azure_endpoint=endpoint,  \n",
    "        api_key=subscription_key,  \n",
    "        api_version=\"2024-05-01-preview\",  \n",
    "    )  \n",
    "      \n",
    "    # Prepare the chat prompt  \n",
    "chat_prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an AI assistant that helps people find information. \"\n",
    "    }\n",
    "]  \n",
    "\n",
    "# Include speech result if speech is enabled  \n",
    "speech_result = chat_prompt  \n",
    "\n",
    "# Generate the completion  \n",
    "completion = client.chat.completions.create(  \n",
    "    model=deployment,  \n",
    "    messages=speech_result,  \n",
    "    max_tokens=800,  \n",
    "    temperature=0.7,  \n",
    "    top_p=0.95,  \n",
    "    frequency_penalty=0,  \n",
    "    presence_penalty=0,  \n",
    "    stop=None,  \n",
    "    stream=False  \n",
    ")  \n",
    "    \n",
    "print(completion.to_json())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! I am an AI assistant here to help you find information. What can I help you with today?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.to_dict()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposal for Planogram Evaluation Using AI\n",
      "\n",
      "Introduction\n",
      "Efficient merchandising is critical for optimizing shelf space, enhancing customer experience, and driving sales. Planograms—visual representations of a store's layout—are integral to achieving this, ensuring product placement aligns with business goals. However, evaluating planograms for compliance, performance, and customer impact is labor-intensive and prone to inconsistencies.\n",
      "\n",
      "Leveraging artificial intelligence (AI) offers a transformative approach. AI-powered solutions can analyze planograms efficiently, providing actionable insights to optimize layouts, ensure compliance, and boost profitability. This proposal outlines a comprehensive plan for implementing AI-based planogram evaluation.\n",
      "\n",
      "Objectives\n",
      "Automate Planogram Evaluation: Reduce the time and effort required to assess planogram compliance and effectiveness.\n",
      "Improve Accuracy: Minimize errors and inconsistencies inherent in manual evaluations.\n",
      "Optimize Shelf Performance: Provide actionable insights to enhance product visibility, customer satisfaction, and sales.\n",
      "Enable Continuous Improvement: Use AI analytics to adapt and improve planograms over time based on performance data.\n",
      "Methodology\n",
      "Data Collection:\n",
      "\n",
      "Gather planogram data, including layouts, product SKUs, and category placements.\n",
      "Capture shelf images or real-time data from IoT-enabled devices and cameras in stores.\n",
      "AI Model Development:\n",
      "\n",
      "Develop machine learning (ML) models for image recognition and natural language processing (NLP) to assess compliance and layout adherence.\n",
      "Train models on historical sales, customer traffic patterns, and planogram data to identify optimal layouts.\n",
      "Evaluation Process:\n",
      "\n",
      "Use computer vision to compare planograms against shelf images, detecting discrepancies like missing or misplaced products.\n",
      "Apply predictive analytics to evaluate how layout changes affect sales and customer behavior.\n",
      "Dashboard and Reporting:\n",
      "\n",
      "Build an interactive dashboard for stakeholders to view compliance scores, key performance indicators (KPIs), and recommendations.\n",
      "Provide detailed reports for actionable insights.\n",
      "Pilot Testing and Rollout:\n",
      "\n",
      "Conduct a pilot in select stores, refine the AI models based on results, and scale implementation across all locations.\n",
      "Results\n",
      "Through pilot testing, the following outcomes are anticipated:\n",
      "\n",
      "Increased Efficiency: Planogram evaluations completed in hours instead of days.\n",
      "Improved Accuracy: Over 95% accuracy in compliance detection compared to manual evaluations.\n",
      "Higher Sales Conversion Rates: Optimized layouts leading to a measurable increase in sales.\n",
      "Scalable Insights: AI-driven insights applicable across multiple locations, reducing operational inefficiencies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "# Example usage\n",
    "file_path = 'summarize.txt'\n",
    "text_content = read_text_file(file_path)\n",
    "print(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Proposal for Planogram Evaluation Using AI\\n\\nIntroduction\\nEfficient merchandising is critical for optimizing shelf space, enhancing customer experience, and driving sales. Planograms—visual representations of a store's layout—are integral to achieving this, ensuring product placement aligns with business goals. However, evaluating planograms for compliance, performance, and customer impact is labor-intensive and prone to inconsistencies.\\n\\nLeveraging artificial intelligence (AI) offers a transformative approach. AI-powered solutions can analyze planograms efficiently, providing actionable insights to optimize layouts, ensure compliance, and boost profitability. This proposal outlines a comprehensive plan for implementing AI-based planogram evaluation.\\n\\nObjectives\\nAutomate Planogram Evaluation: Reduce the time and effort required to assess planogram compliance and effectiveness.\\nImprove Accuracy: Minimize errors and inconsistencies inherent in manual evaluations.\\nOptimize Shelf Performance: Provide actionable insights to enhance product visibility, customer satisfaction, and sales.\\nEnable Continuous Improvement: Use AI analytics to adapt and improve planograms over time based on performance data.\\nMethodology\\nData Collection:\\n\\nGather planogram data, including layouts, product SKUs, and category placements.\\nCapture shelf images or real-time data from IoT-enabled devices and cameras in stores.\\nAI Model Development:\\n\\nDevelop machine learning (ML) models for image recognition and natural language processing (NLP) to assess compliance and layout adherence.\\nTrain models on historical sales, customer traffic patterns, and planogram data to identify optimal layouts.\\nEvaluation Process:\\n\\nUse computer vision to compare planograms against shelf images, detecting discrepancies like missing or misplaced products.\\nApply predictive analytics to evaluate how layout changes affect sales and customer behavior.\\nDashboard and Reporting:\\n\\nBuild an interactive dashboard for stakeholders to view compliance scores, key performance indicators (KPIs), and recommendations.\\nProvide detailed reports for actionable insights.\\nPilot Testing and Rollout:\\n\\nConduct a pilot in select stores, refine the AI models based on results, and scale implementation across all locations.\\nResults\\nThrough pilot testing, the following outcomes are anticipated:\\n\\nIncreased Efficiency: Planogram evaluations completed in hours instead of days.\\nImproved Accuracy: Over 95% accuracy in compliance detection compared to manual evaluations.\\nHigher Sales Conversion Rates: Optimized layouts leading to a measurable increase in sales.\\nScalable Insights: AI-driven insights applicable across multiple locations, reducing operational inefficiencies.\\n\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "predefined_sections = {\n",
    "    \"Introduction\": \"\",\n",
    "    \"Objectives\": \"\",\n",
    "    \"Methodology\": \"\",\n",
    "    \"Results\": \"\",\n",
    "    \"Conclusion\": \"\"\n",
    "}\n",
    "\n",
    "# def extract_text_from_pdf(file_path):\n",
    "#     return \n",
    "\n",
    "def summarize_and_categorize(text, predefined_sections):\n",
    "    prompt = f\"\"\"\n",
    "    The following is a text extracted from a PDF. Summarize the content and categorize it into these sections: {list(predefined_sections.keys())}.\n",
    "    If a section lacks sufficient information, leave it empty and indicate that more input is needed.\n",
    "    Output in Json format\n",
    "\n",
    "    Text: {text}\n",
    "    \"\"\"\n",
    "    chat_prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "    ]  \n",
    "    \n",
    "    completion = client.chat.completions.create(  \n",
    "        model=deployment,  \n",
    "        messages=chat_prompt,  \n",
    "        max_tokens=800,  \n",
    "        temperature=0.7,  \n",
    "        top_p=0.95,  \n",
    "        frequency_penalty=0,  \n",
    "        presence_penalty=0,  \n",
    "        stop=None,  \n",
    "        stream=False  \n",
    "    )  \n",
    "    \n",
    "    return completion.to_dict()['choices'][0]['message']['content']\n",
    "\n",
    "\n",
    "def identify_missing_sections(categorized_summary):\n",
    "    missing_sections = [\n",
    "        section for section, content in categorized_summary.items() if not content or \"input is needed\" in content\n",
    "    ]\n",
    "    return missing_sections\n",
    "\n",
    "def ask_for_user_input(missing_sections):\n",
    "    user_inputs = {}\n",
    "    for section in missing_sections:\n",
    "        user_inputs[section] = input(f\"Please provide more information for the '{section}' section: \")\n",
    "    return user_inputs\n",
    "\n",
    "def process_pdf(file_path, predefined_sections):\n",
    "    # Step 1: Extract text from PDF\n",
    "    # text = extract_text_from_pdf(file_path)\n",
    "    text = read_text_file(file_path)\n",
    "    \n",
    "    # Step 2: Summarize and categorize content\n",
    "    categorized_summary = summarize_and_categorize(text, predefined_sections)\n",
    "\n",
    "    categorized_summary = json.loads(categorized_summary)\n",
    "    \n",
    "    # # Step 3: Check for missing sections\n",
    "    missing_sections = identify_missing_sections(categorized_summary)\n",
    "    \n",
    "    if missing_sections:\n",
    "        print(\"Some sections lack information.\")\n",
    "        # Step 4: Ask user for additional input\n",
    "        user_inputs = ask_for_user_input(missing_sections)\n",
    "        # Step 5: Update categorized summary\n",
    "        for section in missing_sections:\n",
    "            categorized_summary[section] = user_inputs[section]\n",
    "    \n",
    "    return categorized_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some sections lack information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Introduction': 'The proposal suggests leveraging AI to analyze planograms for optimizing layouts and boosting profitability.',\n",
       " 'Objectives': {'Automate Planogram Evaluation': 'Reduce time and effort required for planogram assessment.',\n",
       "  'Improve Accuracy': 'Minimize errors and inconsistencies in manual evaluations.',\n",
       "  'Optimize Shelf Performance': 'Provide insights to enhance product visibility, customer satisfaction, and sales.',\n",
       "  'Enable Continuous Improvement': 'Use AI analytics to adapt and improve planograms over time based on performance data.'},\n",
       " 'Methodology': {'Data Collection': 'Gather planogram data, capture shelf images or real-time data from IoT-enabled devices and cameras in stores.',\n",
       "  'AI Model Development': 'Develop ML models for image recognition and NLP, train models on historical sales, customer traffic patterns, and planogram data.',\n",
       "  'Evaluation Process': 'Use computer vision to compare planograms against shelf images, apply predictive analytics to evaluate how layout changes affect sales and customer behavior.',\n",
       "  'Dashboard and Reporting': 'Build an interactive dashboard for stakeholders to view compliance scores, KPIs, and recommendations, provide detailed reports for actionable insights.',\n",
       "  'Pilot Testing and Rollout': 'Conduct a pilot in select stores, refine the AI models based on results, and scale implementation across all locations.'},\n",
       " 'Results': 'Pilot testing is expected to lead to increased efficiency, improved accuracy, higher sales conversion rates, and scalable insights.',\n",
       " 'Conclusion': 'AI-powered planogram evaluation represents a paradigm shift in retail operations. This solution promises to streamline processes, enhance accuracy, and provide data-driven insights to optimize shelf performance. With a well-structured implementation strategy, businesses can unlock new levels of efficiency and profitability, making AI an indispensable tool in retail merchandising.'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = process_pdf('summarize.txt', predefined_sections)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "endpoint = \"https://<your-form-recognizer-endpoint>.cognitiveservices.azure.com/\"\n",
    "key = \"<your-form-recognizer-key>\"\n",
    "\n",
    "client = DocumentAnalysisClient(endpoint, AzureKeyCredential(key))\n",
    "\n",
    "def extract_text_with_form_recognizer(pdf_path):\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        poller = client.begin_analyze_document(\"prebuilt-read\", document=f)\n",
    "        result = poller.result()\n",
    "        return \" \".join([line.content for page in result.pages for line in page.lines])\n",
    "    \n",
    "def summarize_and_categorize_azure_openai(text, predefined_sections):\n",
    "    prompt = f\"\"\"\n",
    "    Categorize the following text into sections: {list(predefined_sections.keys())}.\n",
    "    If any section is incomplete, indicate it requires more information.\n",
    "\n",
    "    Text: {text}\n",
    "    \"\"\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aurora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
